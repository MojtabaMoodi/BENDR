{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Basics\n",
    "------\n",
    "This covers a fundamental use-case for DN<sup>3</sup>. Here, the TIDNet architecture from *Kostas & Rudzicz 2020\n",
    "(https://doi.org/10.1088/1741-2552/abb7a7)* is evaluated using the Physionet motor dataset in a\n",
    "*\"leave multiple subjects out\"* (aka person-stratified cross validation) training procedure.\n",
    "This means, the number of subjects are divided into approximately evenly numbered sets, and the test performance of\n",
    "each set is evaluated. The remaining sets for each test will be used to develop a neural network classifier.\n",
    "\n",
    "Here we will focus on classifying imagined hand vs. foot movement, which are the runs 6, 10 and 14. So create a\n",
    "configuration for the configuratron that specifies a single dataset, the length of the trials to cut for the dataset\n",
    " (6s), the events we are looking for (T1 and T2), and then to exclude all those sessions that are not 6, 10 and 14\n",
    "(the sessions by default are listed as \"S{subject number}R{run number}.edf\". Finally, due to some issues with a few\n",
    "people's recordings in the dataset, we can ignore those troublemakers. The following is the contents of a file named\n",
    "\"my_config.yml\".\n",
    "\n",
    "```yaml\n",
    "Configuratron:\n",
    "  preload: True\n",
    "\n",
    "use_gpu: False\n",
    "\n",
    "mmidb:\n",
    "  name: \"Physionet MMIDB\"\n",
    "  toplevel: /path/to/eegmmidb\n",
    "  tmin: 0\n",
    "  tlen: 6\n",
    "  data_max: 0.001\n",
    "  data_min: -0.001\n",
    "  events:\n",
    "    - T1\n",
    "    - T2\n",
    "  exclude_sessions:\n",
    "    - \"*R0[!48].edf\"  # equivalently \"*R0[1235679].edf\"\n",
    "    - \"*R1[!2].edf\"   # equivalently \"*R1[134].edf\"\n",
    "  exclude_people:\n",
    "    - S088\n",
    "    - S090\n",
    "    - S092\n",
    "    - S100\n",
    "  train_params:\n",
    "    epochs: 7\n",
    "    batch_size: 4\n",
    "  lr: 0.0001\n",
    "  folds: 5\n",
    "```\n",
    "\n",
    "Notice that in addition to the dataset and special `Configuratron` section we also include a `train_params` with the\n",
    "dataset.\n",
    "This last part is definitely *not mandatory*, it is an arbitrarily named additional set of configuration values that\n",
    "will be used in our experiment, put there for convenience. See it in action below, but if you don't like it,\n",
    "don't use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dn3.configuratron import ExperimentConfig\n",
    "from dn3.trainable.processes import StandardClassification\n",
    "from dn3.trainable.models import TIDNet\n",
    "\n",
    "# Since we are doing a lot of loading, this is nice to suppress some tedious information\n",
    "import mne\n",
    "mne.set_log_level(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First things first, we use `ExperimentConfig`, and the subsequently constructed `DatasetConfig` to rapidly construct\n",
    "our `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding additional configuration entries: dict_keys(['train_params', 'folds', 'lr'])\n",
      "Configuratron found 1 datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning /Volumes/Data/MMI. If there are a lot of files, this may take a while...: 100%|██████████| 4/4 [00:00<00:00,  9.99it/s, extension=.gdf]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset of 315 Preloaded Epoched recordings from 105 people.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Physionet MMIDB: 100%|██████████| 105/105 [00:11<00:00,  9.29person/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Physionet MMIDB | DSID: None | 105 people | 4408 trials | 90 channels | 1536 samples/trial | 256Hz | 0 transforms\n",
      "Constructed 1 channel maps\n",
      "====================\n",
      "Used by 315 recordings:\n",
      "EEG (original(new)): Fc5.(FC5) Fc3.(FC3) Fc1.(FC1) Fcz.(FCZ) Fc2.(FC2) Fc4.(FC4) Fc6.(FC6) C5..(C5) C3..(C3) C1..(C1) Cz..(CZ) C2..(C2) C4..(C4) C6..(C6) Cp5.(CP5) Cp3.(CP3) Cp1.(CP1) Cpz.(CPZ) Cp2.(CP2) Cp4.(CP4) Cp6.(CP6) Fp1.(FP1) Fpz.(FPZ) Fp2.(FP2) Af7.(AF7) Af3.(AF3) Afz.(AFZ) Af4.(AF4) Af8.(AF8) F7..(F7) F5..(F5) F3..(F3) F1..(F1) Fz..(FZ) F2..(F2) F4..(F4) F6..(F6) F8..(F8) Ft7.(FT7) Ft8.(FT8) T7..(T7) T8..(T8) T9..(T9) T10.(T10) Tp7.(TP7) Tp8.(TP8) P7..(P7) P5..(P5) P3..(P3) P1..(P1) Pz..(PZ) P2..(P2) P4..(P4) P6..(P6) P8..(P8) Po7.(PO7) Po3.(PO3) Poz.(POZ) Po4.(PO4) Po8.(PO8) O1..(O1) Oz..(OZ) O2..(O2) Iz..(IZ) \n",
      "EOG (original(new)): \n",
      "REF (original(new)): \n",
      "EXTRA (original(new)): \n",
      "Heuristically Assigned: Fc5.(FC5)  Fc3.(FC3)  Fc1.(FC1)  Fcz.(FCZ)  Fc2.(FC2)  Fc4.(FC4)  Fc6.(FC6)  C5..(C5)  C3..(C3)  C1..(C1)  Cz..(CZ)  C2..(C2)  C4..(C4)  C6..(C6)  Cp5.(CP5)  Cp3.(CP3)  Cp1.(CP1)  Cpz.(CPZ)  Cp2.(CP2)  Cp4.(CP4)  Cp6.(CP6)  Fp1.(FP1)  Fpz.(FPZ)  Fp2.(FP2)  Af7.(AF7)  Af3.(AF3)  Afz.(AFZ)  Af4.(AF4)  Af8.(AF8)  F7..(F7)  F5..(F5)  F3..(F3)  F1..(F1)  Fz..(FZ)  F2..(F2)  F4..(F4)  F6..(F6)  F8..(F8)  Ft7.(FT7)  Ft8.(FT8)  T7..(T7)  T8..(T8)  T9..(T9)  T10.(T10)  Tp7.(TP7)  Tp8.(TP8)  P7..(P7)  P5..(P5)  P3..(P3)  P1..(P1)  Pz..(PZ)  P2..(P2)  P4..(P4)  P6..(P6)  P8..(P8)  Po7.(PO7)  Po3.(PO3)  Poz.(POZ)  Po4.(PO4)  Po8.(PO8)  O1..(O1)  Oz..(OZ)  O2..(O2)  Iz..(IZ) \n",
      "--------------------\n",
      "Excluded []\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "config_filename = 'my_config.yml'\n",
    "experiment = ExperimentConfig(config_filename)\n",
    "ds_config = experiment.datasets['mmidb']\n",
    "\n",
    "dataset = ds_config.auto_construct_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's create a function that makes a new model for each set of training people and a trainable process for\n",
    "`StandardClassification`. The `cuda` argument handles whether the GPU is used to train the neural network if a\n",
    "cuda-compatible PyTorch installation is operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import sys, os\n",
    "# Add the parent directory to the path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from dn3.configuratron.config import DatasetConfig\n",
    "\n",
    "# class Float16Wrapper(DatasetConfig):\n",
    "#     def __init__(self, dataset):\n",
    "#         super().__init__(name=dataset.myname, config=dataset.myconfig)\n",
    "#         self.dataset = dataset\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x, y = self.dataset[idx]\n",
    "#         return x.half(), y  # assume x is float32 and y (label) can stay as-is\n",
    "    \n",
    "class Float16DatasetWrapper:\n",
    "    def __init__(self, dataset):\n",
    "        self._dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self._dataset[idx]\n",
    "        if isinstance(item, tuple):\n",
    "            x, y = item\n",
    "            return x.half(), y\n",
    "        return item.half()  # in case item is a single tensor\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        # Delegate all other attributes/methods to the original dataset\n",
    "        return getattr(self._dataset, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning /Volumes/Data/MMI. If there are a lot of files, this may take a while...: 100%|██████████| 4/4 [00:00<00:00, 113.50it/s, extension=.gdf]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset of 315 Preloaded Epoched recordings from 105 people.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Physionet MMIDB: 100%|██████████| 105/105 [00:10<00:00,  9.79person/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Physionet MMIDB | DSID: None | 105 people | 4408 trials | 90 channels | 1536 samples/trial | 256Hz | 0 transforms\n",
      "Constructed 1 channel maps\n",
      "====================\n",
      "Used by 630 recordings:\n",
      "EEG (original(new)): Fc5.(FC5) Fc3.(FC3) Fc1.(FC1) Fcz.(FCZ) Fc2.(FC2) Fc4.(FC4) Fc6.(FC6) C5..(C5) C3..(C3) C1..(C1) Cz..(CZ) C2..(C2) C4..(C4) C6..(C6) Cp5.(CP5) Cp3.(CP3) Cp1.(CP1) Cpz.(CPZ) Cp2.(CP2) Cp4.(CP4) Cp6.(CP6) Fp1.(FP1) Fpz.(FPZ) Fp2.(FP2) Af7.(AF7) Af3.(AF3) Afz.(AFZ) Af4.(AF4) Af8.(AF8) F7..(F7) F5..(F5) F3..(F3) F1..(F1) Fz..(FZ) F2..(F2) F4..(F4) F6..(F6) F8..(F8) Ft7.(FT7) Ft8.(FT8) T7..(T7) T8..(T8) T9..(T9) T10.(T10) Tp7.(TP7) Tp8.(TP8) P7..(P7) P5..(P5) P3..(P3) P1..(P1) Pz..(PZ) P2..(P2) P4..(P4) P6..(P6) P8..(P8) Po7.(PO7) Po3.(PO3) Poz.(POZ) Po4.(PO4) Po8.(PO8) O1..(O1) Oz..(OZ) O2..(O2) Iz..(IZ) \n",
      "EOG (original(new)): \n",
      "REF (original(new)): \n",
      "EXTRA (original(new)): \n",
      "Heuristically Assigned: Fc5.(FC5)  Fc3.(FC3)  Fc1.(FC1)  Fcz.(FCZ)  Fc2.(FC2)  Fc4.(FC4)  Fc6.(FC6)  C5..(C5)  C3..(C3)  C1..(C1)  Cz..(CZ)  C2..(C2)  C4..(C4)  C6..(C6)  Cp5.(CP5)  Cp3.(CP3)  Cp1.(CP1)  Cpz.(CPZ)  Cp2.(CP2)  Cp4.(CP4)  Cp6.(CP6)  Fp1.(FP1)  Fpz.(FPZ)  Fp2.(FP2)  Af7.(AF7)  Af3.(AF3)  Afz.(AFZ)  Af4.(AF4)  Af8.(AF8)  F7..(F7)  F5..(F5)  F3..(F3)  F1..(F1)  Fz..(FZ)  F2..(F2)  F4..(F4)  F6..(F6)  F8..(F8)  Ft7.(FT7)  Ft8.(FT8)  T7..(T7)  T8..(T8)  T9..(T9)  T10.(T10)  Tp7.(TP7)  Tp8.(TP8)  P7..(P7)  P5..(P5)  P3..(P3)  P1..(P1)  Pz..(PZ)  P2..(P2)  P4..(P4)  P6..(P6)  P8..(P8)  Po7.(PO7)  Po3.(PO3)  Poz.(POZ)  Po4.(PO4)  Po8.(PO8)  O1..(O1)  Oz..(OZ)  O2..(O2)  Iz..(IZ) \n",
      "--------------------\n",
      "Excluded []\n",
      "====================\n",
      "Training:   >> Physionet MMIDB | DSID: None | 63 people | 2646 trials | 20 channels | 1536 samples/trial | 256Hz | 1 transforms\n",
      "Validation: >> Physionet MMIDB | DSID: None | 21 people | 880 trials | 20 channels | 1536 samples/trial | 256Hz | 1 transforms\n",
      "Test:       >> Physionet MMIDB | DSID: None | 21 people | 882 trials | 20 channels | 1536 samples/trial | 256Hz | 1 transforms\n",
      "Creating BENDRClassification using: 20 channels x 1536 samples at 256Hz | 2 targets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mojtaba/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/env/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receptive field: 143 samples | Downsampled by 96 | Overlap of 47 samples | 16 encoded samples/trial\n",
      "Apple M-series GPU detected: training and model execution will be performed on MPS.\n",
      "Loading data with 0 additional workers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c5bc48a9864dac8f07ecc617cf8512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:  14%|#4        | 1/7 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87410ba20486452fb79d9835838c8dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 1/661 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mojtaba/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/env/lib/python3.12/site-packages/torch/nn/functional.py:1545: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m process = StandardClassification(model, metrics=balanced_accuracy)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# metric = process.evaluate(test)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mds_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m results.append(process.evaluate(test)[\u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3/trainable/processes.py:719\u001b[39m, in \u001b[36mStandardClassification.fit\u001b[39m\u001b[34m(self, training_dataset, epochs, validation_dataset, step_callback, epoch_callback, batch_size, warmup_frac, retain_best, balance_method, **loader_kwargs)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, training_dataset, epochs=\u001b[32m1\u001b[39m, validation_dataset=\u001b[38;5;28;01mNone\u001b[39;00m, step_callback=\u001b[38;5;28;01mNone\u001b[39;00m, epoch_callback=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    671\u001b[39m         batch_size=\u001b[32m8\u001b[39m, warmup_frac=\u001b[32m0.2\u001b[39m, retain_best=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, balance_method=\u001b[38;5;28;01mNone\u001b[39;00m, **loader_kwargs):\n\u001b[32m    672\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[33;03m    sklearn/keras-like convenience method to simply proceed with training across multiple epochs of the provided\u001b[39;00m\n\u001b[32m    674\u001b[39m \u001b[33;03m    dataset\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    717\u001b[39m \u001b[33;03m                     Validation metrics after each epoch of training as a pandas dataframe\u001b[39;00m\n\u001b[32m    718\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mStandardClassification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m                                                   \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m                                                   \u001b[49m\u001b[43mwarmup_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup_frac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_best\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretain_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m                                                   \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m                                                   \u001b[49m\u001b[43mbalance_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbalance_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m                                                   \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mloader_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3/trainable/processes.py:566\u001b[39m, in \u001b[36mBaseProcess.fit\u001b[39m\u001b[34m(self, training_dataset, epochs, validation_dataset, step_callback, resume_epoch, resume_iteration, log_callback, validation_callback, epoch_callback, batch_size, warmup_frac, retain_best, validation_interval, train_log_interval, **loader_kwargs)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m    565\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._get_batch(data_iterator)\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     train_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m     train_metrics[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.optimizer.param_groups[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmomentum\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.optimizer.defaults:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3/trainable/processes.py:278\u001b[39m, in \u001b[36mBaseProcess.train_step\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *inputs):\n\u001b[32m    277\u001b[39m     \u001b[38;5;28mself\u001b[39m.train(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.calculate_loss(inputs, outputs)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mself\u001b[39m.backward(loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3/trainable/processes.py:653\u001b[39m, in \u001b[36mStandardClassification.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *inputs):\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.classifier, Classifier) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classifier.return_features:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m         prediction, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    655\u001b[39m         prediction = \u001b[38;5;28mself\u001b[39m.classifier(*inputs[:-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3/trainable/models.py:211\u001b[39m, in \u001b[36mClassifier.forward\u001b[39m\u001b[34m(self, *x)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03mPerforms a forward pass through the classifier, separating feature extraction and classification.\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03mReturns both the classification output and features if return_features is True, otherwise returns only the classification output.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m \u001b[33;03m    tuple or torch.Tensor: (classification output, features) if return_features is True, else classification output only.\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m classification_output = \u001b[38;5;28mself\u001b[39m.classifier_forward(features)\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (classification_output, features) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_features \u001b[38;5;28;01melse\u001b[39;00m classification_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3_ext.py:98\u001b[39m, in \u001b[36mBENDRClassification.features_forward\u001b[39m\u001b[34m(self, *x)\u001b[39m\n\u001b[32m     95\u001b[39m     encoded += embeddings.unsqueeze(-\u001b[32m1\u001b[39m).expand_as(encoded)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m context = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontextualizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# return self.projection_mlp(context[:, :, 0])\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# return nn.functional.adaptive_max_pool1d(context, output_size=1)\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m context[:, :, -\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3_ext.py:589\u001b[39m, in \u001b[36mBENDRContextualizer.forward\u001b[39m\u001b[34m(self, x, mask_t, mask_c)\u001b[39m\n\u001b[32m    587\u001b[39m         mask_t = _make_mask((bs, seq), \u001b[38;5;28mself\u001b[39m.p_t, x.shape[-\u001b[32m1\u001b[39m], \u001b[38;5;28mself\u001b[39m.mask_t_span)\n\u001b[32m    588\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask_c \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.p_c > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m         mask_c = \u001b[43m_make_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmask_c_span\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask_t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    592\u001b[39m     x.transpose(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)[mask_t] = \u001b[38;5;28mself\u001b[39m.mask_replacement\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityofWaterloo/Think/Time Management/UWaterloo/Research/my research/BENDR/dn3_ext.py:237\u001b[39m, in \u001b[36m_make_mask\u001b[39m\u001b[34m(shape, p, total, span, allow_no_inds)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(shape[\u001b[32m0\u001b[39m]):\n\u001b[32m    236\u001b[39m     mask_seeds = []\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_no_inds \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mask_seeds \u001b[38;5;129;01mand\u001b[39;00m p > \u001b[32m0\u001b[39m:\n\u001b[32m    238\u001b[39m         mask_seeds = np.nonzero(np.random.rand(total) < p)[\u001b[32m0\u001b[39m]\n\u001b[32m    240\u001b[39m     mask[i, _make_span_from_seeds(mask_seeds, span, total=total)] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import objgraph\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Add the parent directory to the path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import utils\n",
    "from dn3_ext import BENDRClassification\n",
    "from dn3.metrics.base import balanced_accuracy\n",
    "from result_tracking import ThinkerwiseResultTracker\n",
    "\n",
    "results = ThinkerwiseResultTracker()\n",
    "\n",
    "for ds_name, ds in (experiment.datasets.items()):\n",
    "        added_metrics, retain_best, _ = utils.get_ds_added_metrics(ds_name, '../configs/metrics.yml')\n",
    "        for training, validation, test in utils.get_lmoso_iterator(ds_name, ds):\n",
    "                # training = Float16DatasetWrapper(training)\n",
    "                # validation = Float16DatasetWrapper(validation)\n",
    "                # test = Float16DatasetWrapper(test)\n",
    "                model = BENDRClassification.from_dataset(training)\n",
    "                model.load_pretrained_modules(experiment.encoder_weights, experiment.context_weights, freeze_encoder=True)\n",
    "                # model = model.half()\n",
    "\n",
    "\n",
    "                process = StandardClassification(model, metrics=balanced_accuracy)\n",
    "                # metric = process.evaluate(test)\n",
    "                process.fit(training_dataset=training, validation_dataset=validation, **ds_config.train_params)\n",
    "\n",
    "                results.append(process.evaluate(test)['Accuracy'])\n",
    "\n",
    "                print(results)\n",
    "                print(\"Average accuracy: {:.2%}\".format(sum(results)/len(results)))\n",
    "                # import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name}, dtype: {param.dtype}\")\n",
    "\n",
    "for name, buffer in model.named_buffers():\n",
    "    print(f\"Buffer: {name}, dtype: {buffer.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "d32 = dir(training)\n",
    "d16 = dir(Float16Wrapper(training))\n",
    "# compare the two lists\n",
    "diff = set(d32) - set(d16)\n",
    "print(\"Difference in attributes:\")\n",
    "for item in diff:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(training))\n",
    "print(training[0][1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BENDRClassification.from_dataset(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size_mb(model):\n",
    "    total_bytes = 0\n",
    "    for param in model.parameters():\n",
    "        total_bytes += param.nelement() * param.element_size()\n",
    "    for buffer in model.buffers():\n",
    "        total_bytes += buffer.nelement() * buffer.element_size()\n",
    "    return total_bytes / (1024 ** 2)  # Convert to megabytes (MB)\n",
    "\n",
    "# Example usage:\n",
    "size_mb = get_model_size_mb(model)\n",
    "print(f\"Model size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_mb = get_model_size_mb(model)\n",
    "print(f\"Model size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(ds_config.train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = next(process.classifier.parameters()).dtype\n",
    "print(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process = make_model_and_process()\n",
    "# print the dtype of the model\n",
    "print(process.classifier)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'total': total, 'trainable': trainable}\n",
    "\n",
    "count_parameters(process.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_model_and_process():\n",
    "    tidnet = TIDNet.from_dataset(dataset)\n",
    "    return StandardClassification(tidnet, cuda=experiment.use_gpu, learning_rate=ds_config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "That's pretty much it! We use a helper that initializes a TIDNet from any `Dataset/Thinker/EpochedRecording` and wrap\n",
    "it with a `StandardClassification` process. Invoking this process will train the classifier.\n",
    "Have a look through all the `trainable.processes`, they can wrap the *same model* to learn in stages (e.g. some sort\n",
    " of fine-tuning procedure from a general model -- covered in `examples/finetuning.ipynb`).\n",
    "\n",
    "Now, we loop through five folds, *leaving multiple subjects out* (`dataset.lmso()`), fit the classifier,\n",
    "then check the test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for training, validation, test in dataset.lmso(ds_config.folds):\n",
    "    process = make_model_and_process()\n",
    "\n",
    "    process.fit(training_dataset=training, validation_dataset=validation, **ds_config.train_params)\n",
    "\n",
    "    results.append(process.evaluate(test)['Accuracy'])\n",
    "\n",
    "print(results)\n",
    "print(\"Average accuracy: {:.2%}\".format(sum(results)/len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check out how we passed the train_params to `.fit()`, we could specify more arguments for `.fit()` by just adding them\n",
    "to this section in the configuration.\n",
    "\n",
    "Say we wanted to *instead*, get the performance of *each* person in the test fold independently. We could replace the\n",
    "code above with a very simple alternative, that *leaves one subject out* or `.loso()`, that specifically.\n",
    "It would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = dict()\n",
    "for training, validation, test in dataset.lmso(ds_config.folds):\n",
    "    process = make_model_and_process()\n",
    "\n",
    "    process.fit(training_dataset=training, validation_dataset=validation,\n",
    "                epochs=ds_config.train_params.epochs,\n",
    "                batch_size=ds_config.train_params.batch_size)\n",
    "\n",
    "    for _, _, test_thinker in test.loso():\n",
    "        results[test_thinker.person_id] = process.evaluate(test_thinker)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc = sum(v['Accuracy'] for v in results.values()) / len(results)\n",
    "print(\"Average accuracy: {:.2%}\".format(avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Try filling in your own values to `my_config.yml` to run these examples on your next read through."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
